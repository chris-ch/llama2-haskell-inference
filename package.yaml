name:                llama2-haskell-inference
version:             0.1.0.0
github:              "githubuser/llama2-haskell-inference"
license:             MIT
author:              "Christophe Alexandre"
maintainer:          "christophe.alexandre@pm.me"
copyright:           "2023 Christophe Alexandre"

extra-source-files:
- README.md
- CHANGELOG.md

# Metadata used when publishing your package
# synopsis:            Short description of your package
# category:            Command line

# To avoid duplicated efforts in documentation and dealing with the
# complications of embedding Haddock markup inside cabal files, it is
# common to point users to the README.md file.
description:         Please see the README on GitHub at <https://github.com/chris-ch/llama2-haskell-inference#readme>

dependencies:
  - base >= 4.7 && < 5
  - random
  - linear
  - matrices
  - bytestring
  - binary
  - array
  - text
  - directory
  - filepath
  - vector
  - split
  - mtl
  - time

ghc-options:
  - -Wall
  - -Wcompat
  - -Widentities
  - -Wincomplete-record-updates
  - -Wincomplete-uni-patterns
#  - -Wmissing-export-lists
  - -Wmissing-home-modules
  - -Wpartial-fields
  - -Wredundant-constraints
  - -O2

library:
  source-dirs: project/src

executables:
  cli-app:
    main: Main.hs
    source-dirs:
      - project/cli-app
      - project/src
    ghc-options:
      - -threaded
      - -rtsopts
      - -with-rtsopts=-N
    dependencies:
      - optparse-applicative
    language: Haskell2010

tests:
  project-test:
    main: Spec.hs
    source-dirs:
      - project/test
      - project/src
    ghc-options:
      - -threaded
      - -rtsopts
      - -with-rtsopts=-N
    dependencies:
      - hspec
    language: Haskell2010
