name:                llama2-haskell-inference
version:             0.1.0.0
github:              "githubuser/llama2-haskell-inference"
license:             MIT
author:              "Christophe Alexandre"
maintainer:          "christophe.alexandre@pm.me"
copyright:           "2023 Christophe Alexandre"

extra-source-files:
- README.md
- CHANGELOG.md

# Metadata used when publishing your package
# synopsis:            Short description of your package
# category:            Command line

# To avoid duplicated efforts in documentation and dealing with the
# complications of embedding Haddock markup inside cabal files, it is
# common to point users to the README.md file.
description:         Please see the README on GitHub at <https://github.com/chris-ch/llama2-haskell-inference#readme>

dependencies:
- base >= 4.7 && < 5
- random
- optparse-applicative

ghc-options:
- -Wall
- -Wcompat
- -Widentities
- -Wincomplete-record-updates
- -Wincomplete-uni-patterns
- -Wmissing-export-lists
- -Wmissing-home-modules
- -Wpartial-fields
- -Wredundant-constraints

library:
  source-dirs: project/src
  dependencies: hmatrix

executables:
  cli-app:
    main:                Main.hs
    source-dirs:         project/cli-app
    ghc-options:
    - -threaded
    - -rtsopts
    - -with-rtsopts=-N
    dependencies:
    - project

tests:
  project-test:
    main:                Spec.hs
    source-dirs:         project/test
    ghc-options:
    - -threaded
    - -rtsopts
    - -with-rtsopts=-N
